# python continual_learn_clip.py --label_set vehicle_7 --use_difference_of_query --class_size 1000 --num_of_buckets 2 
# python continual_learn_clip.py --label_set vehicle_7 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --pretrained --train_mode freeze
# python continual_learn_clip.py --label_set vehicle_7 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode freeze
# python continual_learn_clip.py --label_set vehicle_7 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode freeze
# python continual_learn_clip.py --label_set vehicle_7 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --train_bucket future
# python continual_learn_clip.py --label_set vehicle_7 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --pretrained --train_mode freeze --train_bucket future
# python continual_learn_clip.py --label_set vehicle_7 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode freeze --train_bucket future
# python continual_learn_clip.py --label_set vehicle_7 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode freeze --train_bucket future


# python continual_learn_clip.py --label_set vehicle_7 --class_size 1000 --num_of_buckets 2 
# python continual_learn_clip.py --label_set vehicle_7 --class_size 1000 --num_of_buckets 2 --pretrained --train_mode freeze
# python continual_learn_clip.py --label_set vehicle_7 --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode freeze
# python continual_learn_clip.py --label_set vehicle_7 --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode freeze
# python continual_learn_clip.py --label_set vehicle_7 --class_size 1000 --num_of_buckets 2 --train_bucket future
# python continual_learn_clip.py --label_set vehicle_7 --class_size 1000 --num_of_buckets 2 --pretrained --train_mode freeze --train_bucket future
# python continual_learn_clip.py --label_set vehicle_7 --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode freeze --train_bucket future
# python continual_learn_clip.py --label_set vehicle_7 --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode freeze --train_bucket future


# python continual_learn_clip.py --label_set cifar10 --use_difference_of_query --class_size 1000 --num_of_buckets 2 
# python continual_learn_clip.py --label_set cifar10 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --pretrained --train_mode freeze
# python continual_learn_clip.py --label_set cifar10 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode freeze
# python continual_learn_clip.py --label_set cifar10 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode freeze
# python continual_learn_clip.py --label_set cifar10 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --train_bucket future
# python continual_learn_clip.py --label_set cifar10 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --pretrained --train_mode freeze --train_bucket future
# python continual_learn_clip.py --label_set cifar10 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode freeze --train_bucket future
# python continual_learn_clip.py --label_set cifar10 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode freeze --train_bucket future


# python continual_learn_clip.py --label_set cifar10 --class_size 1000 --num_of_buckets 2 
# python continual_learn_clip.py --label_set cifar10 --class_size 1000 --num_of_buckets 2 --pretrained --train_mode freeze
# python continual_learn_clip.py --label_set cifar10 --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode freeze
# python continual_learn_clip.py --label_set cifar10 --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode freeze
# python continual_learn_clip.py --label_set cifar10 --class_size 1000 --num_of_buckets 2 --pretrained --train_mode finetune
# python continual_learn_clip.py --label_set cifar10 --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode finetune
# python continual_learn_clip.py --label_set cifar10 --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode finetune
# python continual_learn_clip.py --label_set cifar10 --class_size 1000 --num_of_buckets 2 --train_bucket future
# python continual_learn_clip.py --label_set cifar10 --class_size 1000 --num_of_buckets 2 --pretrained --train_mode freeze --train_bucket future
# python continual_learn_clip.py --label_set cifar10 --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode freeze --train_bucket future
# python continual_learn_clip.py --label_set cifar10 --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode freeze --train_bucket future
# python continual_learn_clip.py --label_set cifar10 --class_size 1000 --num_of_buckets 2 --pretrained --train_mode finetune --train_bucket future
# python continual_learn_clip.py --label_set cifar10 --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode finetune --train_bucket future
# python continual_learn_clip.py --label_set cifar10 --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode finetune --train_bucket future

# python continual_learn_clip.py --label_set cifar100 --use_difference_of_query --class_size 1000 --num_of_buckets 2 
# python continual_learn_clip.py --label_set cifar100 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --pretrained --train_mode freeze
# python continual_learn_clip.py --label_set cifar100 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --pretrained --train_mode finetune
# python continual_learn_clip.py --label_set cifar100 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode freeze
# python continual_learn_clip.py --label_set cifar100 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode freeze
# python continual_learn_clip.py --label_set cifar100 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --train_bucket future
# python continual_learn_clip.py --label_set cifar100 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --pretrained --train_mode freeze --train_bucket future
# python continual_learn_clip.py --label_set cifar100 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --pretrained --train_mode finetune --train_bucket future
# python continual_learn_clip.py --label_set cifar100 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode freeze --train_bucket future
# python continual_learn_clip.py --label_set cifar100 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode freeze --train_bucket future

# python continual_learn_clip.py --label_set cifar100 --class_size 1000 --num_of_buckets 2 
# python continual_learn_clip.py --label_set cifar100 --class_size 1000 --num_of_buckets 2 --pretrained --train_mode freeze
# python continual_learn_clip.py --label_set cifar100 --class_size 1000 --num_of_buckets 2 --pretrained --train_mode finetune
# python continual_learn_clip.py --label_set cifar100 --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode freeze
# python continual_learn_clip.py --label_set cifar100 --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode freeze
# python continual_learn_clip.py --label_set cifar100 --class_size 1000 --num_of_buckets 2 --train_bucket future
# python continual_learn_clip.py --label_set cifar100 --class_size 1000 --num_of_buckets 2 --pretrained --train_mode freeze --train_bucket future
# python continual_learn_clip.py --label_set cifar100 --class_size 1000 --num_of_buckets 2 --pretrained --train_mode finetune --train_bucket future
# python continual_learn_clip.py --label_set cifar100 --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode freeze --train_bucket future
# python continual_learn_clip.py --label_set cifar100 --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode freeze --train_bucket future


# python continual_learn_clip.py --label_set cifar100 --query_title "" --label_set cifar100 --class_size 1000  --clip_dataset_path /scratch/zhiqiu/yfcc100m_all/clip_dataset/images_minbyte_10_valid_uploaded_date_jan_31/clip_dataset_no_pre_prompt/ --num_of_buckets 2 --train_mode clip_feature
# python continual_learn_clip.py --query_title "" --label_set cifar100 --lmb 10. --use_difference_of_query --class_size 1000  --clip_dataset_path /scratch/zhiqiu/yfcc100m_all/clip_dataset/images_minbyte_10_valid_uploaded_date_jan_31/clip_dataset_no_pre_prompt/ --num_of_buckets 2 --train_mode clip_feature
# python continual_learn_clip.py --query_title "" --label_set cifar100 --lmb 1. --use_difference_of_query --class_size 1000  --clip_dataset_path /scratch/zhiqiu/yfcc100m_all/clip_dataset/images_minbyte_10_valid_uploaded_date_jan_31/clip_dataset_no_pre_prompt/ --num_of_buckets 2 --train_mode clip_feature
# python continual_learn_clip.py --label_set cifar100 --lmb 10. --use_difference_of_query --class_size 1000 --num_of_buckets 2 --train_mode clip_feature

# python continual_learn_clip.py --query_title "" --label_set imagenet1K --class_size 1000  --clip_dataset_path /scratch/zhiqiu/yfcc100m_all/clip_dataset/images_minbyte_10_valid_uploaded_date_jan_31/clip_dataset_no_pre_prompt/ --num_of_buckets 2 --train_mode clip_feature
# python continual_learn_clip.py --query_title "" --label_set imagenet1K --lmb 100. --use_difference_of_query --class_size 1000  --clip_dataset_path /scratch/zhiqiu/yfcc100m_all/clip_dataset/images_minbyte_10_valid_uploaded_date_jan_31/clip_dataset_no_pre_prompt/ --num_of_buckets 2 --train_mode clip_feature
# python continual_learn_clip.py --query_title "" --label_set imagenet1K --lmb 1. --use_difference_of_query --class_size 1000  --clip_dataset_path /scratch/zhiqiu/yfcc100m_all/clip_dataset/images_minbyte_10_valid_uploaded_date_jan_31/clip_dataset_no_pre_prompt/ --num_of_buckets 2 --train_mode clip_feature
# python continual_learn_clip.py --label_set imagenet1K --lmb 100. --use_difference_of_query --class_size 1000 --num_of_buckets 2 --train_mode clip_feature

# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --arch mlp --train_mode clip_feature
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --arch mlp --train_mode clip_feature --train_bucket future
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --arch linear --train_mode clip_feature
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --arch linear --train_mode clip_feature --train_bucket future

# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --use_difference_of_query --class_size 1000 --num_of_buckets 2 
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --pretrained --train_mode freeze
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --pretrained --train_mode finetune
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode freeze
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode freeze
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --train_bucket future
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --pretrained --train_mode freeze --train_bucket future
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --pretrained --train_mode finetune --train_bucket future
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode freeze --train_bucket future
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --use_difference_of_query --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode freeze --train_bucket future


# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --class_size 1000 --num_of_buckets 2 --arch mlp --train_mode clip_feature
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --class_size 1000 --num_of_buckets 2 --arch mlp --train_mode clip_feature --train_bucket future
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --class_size 1000 --num_of_buckets 2 --arch linear --train_mode clip_feature
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --class_size 1000 --num_of_buckets 2 --arch linear --train_mode clip_feature --train_bucket future


# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --class_size 1000 --num_of_buckets 2 
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --class_size 1000 --num_of_buckets 2 --pretrained --train_mode freeze
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --class_size 1000 --num_of_buckets 2 --pretrained --train_mode finetune
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode freeze
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode freeze
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --class_size 1000 --num_of_buckets 2 --train_bucket future
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --class_size 1000 --num_of_buckets 2 --pretrained --train_mode freeze --train_bucket future
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --class_size 1000 --num_of_buckets 2 --selfsupervised moco_v2 --train_mode freeze --train_bucket future
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --class_size 1000 --num_of_buckets 2 --selfsupervised byol --train_mode freeze --train_bucket future


# New version
# python continual_learn_clip.py --label_set vehicle_7 --class_size 1000 --use_max_score --train_mode clip_feature
# python continual_learn_clip.py --label_set cifar10 --class_size 1000 --use_max_score --train_mode clip_feature
# python continual_learn_clip.py --label_set cifar100 --class_size 1000 --use_max_score --train_mode clip_feature
# python continual_learn_clip.py --label_set imagenet1K --epoch 80 --step 25 --class_size 1000 --use_max_score --train_mode clip_feature

# python continual_learn_clip.py --label_set vehicle_7 --class_size 1000 --use_max_score --query_title none --train_mode clip_feature
# python continual_learn_clip.py --label_set cifar10 --class_size 1000 --use_max_score --query_title none --train_mode clip_feature
# python continual_learn_clip.py --label_set cifar100 --class_size 1000 --use_max_score --query_title none --train_mode clip_feature
# python continual_learn_clip.py --label_set imagenet1K  --epoch 80 --step 25 --class_size 1000 --use_max_score --query_title none --train_mode clip_feature


import os
import random
import shutil
import time
import warnings

import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.distributed as dist
import torch.optim
import torch.multiprocessing as mp
import torch.utils.data
import torch.utils.data.distributed
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torchvision.models as models

from glob import glob
from tqdm import tqdm
import random

from utils import sort_metadata_by_date, divide, save_obj_as_pickle, load_pickle
from training_utils import make_optimizer, make_scheduler, make_model, make_loader, make_clip_loader, train, test, get_imgnet_transforms
from prepare_clip_dataset import get_save_path, QUERY_TITLE_DICT, LABEL_SETS

# For each bucket, make sure at least VAL_SET_SIZE + TEST_SET_SIZE exist
VAL_SET_SIZE = 50
TEST_SET_SIZE = 50
TRAIN_SET_SIZE = 400

import argparse
argparser = argparse.ArgumentParser()
argparser.add_argument("--clip_dataset_path", 
                        # default='/scratch/zhiqiu/yfcc100m_all/images_minbyte_10_valid_uploaded_date_jan_25',
                        default='/scratch/zhiqiu/yfcc100m_all/clip_dataset/images_minbyte_10_valid_uploaded_date_jan_31/clip_dataset/',
                        help="The folder that will store the curated dataset")
argparser.add_argument("--label_set", 
                        default='vehicle_7', choices=LABEL_SETS,
                        help="The label sets")
argparser.add_argument("--use_difference_of_query", 
                        action='store_true',
                        help="Whether or not to use difference of query")
argparser.add_argument('--class_size', default=1000, type=int,
                       help='number of samples per class')
argparser.add_argument("--lmb", 
                        default=1., type=float,
                        help="The difference of query feature ratio")
argparser.add_argument("--use_max_score", 
                        action='store_true',
                        help="Keep the max scoring images")
argparser.add_argument('--train_mode', default='finetune', choices=['finetune', 'freeze', 'clip_feature'],
                       help='Train mode')
argparser.add_argument("--query_title", 
                        default='photo', 
                        choices=QUERY_TITLE_DICT.keys(),
                        help="The query title")
argparser.add_argument('--num_of_buckets', default=2, type=int,
                       metavar='N',
                       help='Divide by num_of_buckets (default: 2)')
argparser.add_argument('--train_bucket', default='past', choices=['past', 'future'],
                       help='Training bucket')
argparser.add_argument('-a', '--arch', metavar='ARCH', default='resnet50',
                       help='model architecture (default: resnet50). Can also choose mlp for a 2 layer mlp')
argparser.add_argument('--pretrained', dest='pretrained', action='store_true',
                       help='use imagenet pre-trained model')
argparser.add_argument('--selfsupervised', default=None, choices=['moco_v2', 'byol', 'deepcluster', 'relativeloc', 'rot'],
                       help='name of self supervised model')
argparser.add_argument('--epoch', default=150, type=int, metavar='N',
                       help='number of total epochs to run')
argparser.add_argument('--step', default=60, type=int, metavar='N',
                       help='step size for lr decay')
argparser.add_argument('--batch_size', default=64, type=int,
                       metavar='N',
                       help='mini-batch size (default: 64)')
argparser.add_argument('--num_workers', default=4, type=int,
                       help='num_workers (default: 4)')
argparser.add_argument('--lr', '--learning-rate', default=0.1, type=float,
                       metavar='LR', help='initial learning rate', dest='lr')
argparser.add_argument('--nn_size', default=10000, type=int,
                       help='number of samples per class for initial search of top NN')
# argparser.add_argument('--momentum', default=0.9, type=float, metavar='M',
#                     help='momentum')
# argparser.add_argument('--wd', '--weight-decay', default=1e-5, type=float,
#                     metavar='W', help='weight decay (default: 1e-5)',
#                     dest='weight_decay')


def divide_data_by_date(query_dict, num_of_buckets=2, date='date_uploaded', train_mode='finetune'):
    tag_dict_divided_by_date = []
    for b in range(num_of_buckets):
        sub_tag_dict = {}
        for tag in query_dict:
            sub_tag_dict[tag] = None
        tag_dict_divided_by_date.append(sub_tag_dict)

    for tag in query_dict:
        if train_mode in ['clip_feature', 'nearest_nn', 'nearest_center']:
            sorted_tag_list = sort_metadata_by_date(query_dict[tag]['metadata'], date=date, features=query_dict[tag]['features'])
        else:
            sorted_tag_list = sort_metadata_by_date(query_dict[tag]['metadata'], date=date)
        sorted_tag_chunks = divide(sorted_tag_list, num_of_buckets)
        
        for i, sorted_tag_chunk in enumerate(sorted_tag_chunks):
            random.shuffle(sorted_tag_chunk)
            val_set = sorted_tag_chunk[:VAL_SET_SIZE]
            test_set = sorted_tag_chunk[VAL_SET_SIZE:VAL_SET_SIZE+TEST_SET_SIZE]
            train_set = sorted_tag_chunk[VAL_SET_SIZE+TEST_SET_SIZE:]

            tag_dict_divided_by_date[i][tag] = {
                'train_set' : train_set,
                'val_set' : val_set,
                'test_set' : test_set,
                'all' : sorted_tag_chunk
            }
    
    return tag_dict_divided_by_date


def get_loaders_from_tag_dict(tag_dict,
                              train_transform,
                              test_transform,
                              batch_size=64, 
                              num_workers=4):
    class_names = list(tag_dict.keys())
    all_items = []
    train_set = []
    val_set = []
    test_set = []
    for idx, class_name in enumerate(class_names):
        all_items += [(meta.get_path(), idx) for meta in tag_dict[class_name]['all']]
        val_set += [(meta.get_path(), idx) for meta in tag_dict[class_name]['val_set']]
        test_set += [(meta.get_path(), idx) for meta in tag_dict[class_name]['test_set']]
        train_set += [(meta.get_path(), idx) for meta in tag_dict[class_name]['train_set']]

    train_loader = make_loader(train_set, train_transform, shuffle=True, batch_size=batch_size, num_workers=num_workers)
    val_loader = make_loader(val_set, test_transform, shuffle=False, batch_size=batch_size, num_workers=num_workers)
    test_loader = make_loader(test_set, test_transform, shuffle=False, batch_size=batch_size, num_workers=num_workers)
    all_loader = make_loader(all_items, test_transform, shuffle=False, batch_size=batch_size, num_workers=num_workers)
    return {
        'all' : all_loader,
        'train' : train_loader,
        'val' : val_loader,
        'test' : test_loader
    }

def get_clip_loaders_from_tag_dict(tag_dict,
                                   batch_size=64, 
                                   num_workers=4):
    class_names = list(tag_dict.keys())
    all_items = []
    train_set = []
    val_set = []
    test_set = []
    for idx, class_name in enumerate(class_names):
        all_items += [(x[1], idx) for x in tag_dict[class_name]['all']]
        val_set += [(x[1], idx) for x in tag_dict[class_name]['val_set']]
        test_set += [(x[1], idx) for x in tag_dict[class_name]['test_set']]
        train_set += [(x[1], idx) for x in tag_dict[class_name]['train_set']]

    train_loader = make_clip_loader(train_set, shuffle=True, batch_size=batch_size, num_workers=num_workers)
    val_loader = make_clip_loader(val_set, shuffle=False, batch_size=batch_size, num_workers=num_workers)
    test_loader = make_clip_loader(test_set, shuffle=False, batch_size=batch_size, num_workers=num_workers)
    all_loader = make_clip_loader(all_items, shuffle=False, batch_size=batch_size, num_workers=num_workers)
    return {
        'all' : all_loader,
        'train' : train_loader,
        'val' : val_loader,
        'test' : test_loader
    }

def get_loaders_from_tag_dicts(tag_dicts,
                               train_transform,
                               test_transform,
                               batch_size=64, 
                               num_workers=4,
                               train_mode='finetune'):
    loaders = {}
    for i, tag_dict in enumerate(tag_dicts):
        if train_mode == 'clip_feature':
            loaders[i] = get_clip_loaders_from_tag_dict(
                            tag_dict,
                            batch_size=batch_size, 
                            num_workers=num_workers,
                        )

        else:
            loaders[i] = get_loaders_from_tag_dict(
                            tag_dict,
                            train_transform,
                            test_transform,
                            batch_size=batch_size, 
                            num_workers=num_workers,
                        )
                     
    return loaders
    
    
    
if __name__ == "__main__":
    args = argparser.parse_args()

    save_path = get_save_path(args)
    # lmb_str = f"lmb_{args.lmb}" if args.lmb != 1. else ""
    # save_path = os.path.join(args.clip_dataset_path, args.label_set, f"size_{args.class_size}_doq_{args.use_difference_of_query}{lmb_str}")

    query_dict_path = os.path.join(save_path, "query_dict.pickle")
    query_dict  = load_pickle(query_dict_path)

    # clip_feature_str = "" if args.train_mode != 'clip_feature' else "_clip"
    # tag_dict_path = os.path.join(save_path, f"tag_dict_divided_by_date{clip_feature_str}.pickle")
    tag_dict_path = os.path.join(save_path, f"tag_dict_divided_by_date.pickle")
    if os.path.exists(tag_dict_path):
        print(tag_dict_path+" exists")
        tag_dict_divided_by_date = load_pickle(tag_dict_path)
    else:
        tag_dict_divided_by_date = divide_data_by_date(query_dict, date='date_uploaded', num_of_buckets=args.num_of_buckets, train_mode=args.train_mode)
        save_obj_as_pickle(tag_dict_path, tag_dict_divided_by_date)
        print(f"saved to {tag_dict_path}")

    train_transform, test_transform = get_imgnet_transforms()
    loaders_divided_by_date = get_loaders_from_tag_dicts(
                                    tag_dict_divided_by_date,
                                    train_transform,
                                    test_transform,
                                    batch_size=args.batch_size, 
                                    num_workers=args.num_workers,
                                    train_mode=args.train_mode
                                )

    if args.train_mode == 'clip_feature':
        print("Just generating the feature")
        exit(0)

    assert args.num_of_buckets == 2
    network = make_model(args.arch, args.pretrained, args.selfsupervised, output_size=len(list(query_dict.keys())), train_mode=args.train_mode)
    first_loader = loaders_divided_by_date[0]
    second_loader = loaders_divided_by_date[1]
    if args.train_bucket == 'past':
        network = train(first_loader['train'], first_loader['val'], first_loader['test'], network, epochs=args.epoch, lr=args.lr, step_size=args.step)
    else:
        network = train(second_loader['train'], second_loader['val'], second_loader['test'], network, epochs=args.epoch, lr=args.lr, step_size=args.step)

    # save_model_dir = "./saved_models"
    # if not os.path.exists(save_model_dir):
    #     os.makedirs(save_model_dir)
    # save_loc = f'{save_model_dir}{args.train_mode}_train_on_{args.train_bucket}.pickle'
    print("On test set of first bucket")
    test(first_loader['test'], network, save_loc=None)
    print("On all images of first bucket")
    test(first_loader['all'], network)
    print("On test set of second bucket")
    test(second_loader['test'], network)
    print("On all images of second bucket")
    test(second_loader['all'], network)
