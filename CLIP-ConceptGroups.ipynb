{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "tamil-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./CLIP\")\n",
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "from IPython.display import Image as ImageDisplay\n",
    "from utils import load_pickle, save_obj_as_pickle\n",
    "import numpy as np\n",
    "from matplotlib.image import imread\n",
    "from matplotlib.pyplot import figure, imshow, axis\n",
    "from jupyter_utils import plot_time_jupyter, plot_scores_jupyter\n",
    "import time\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-sleeping",
   "metadata": {},
   "source": [
    "# Below cell contains several datasets that I have prepared for you. These include:\n",
    "- Smallest (for debug purpose only, since this dataset is too small to retrieve anything meaningful)\n",
    "- Medium (2740000 images, you may try your prompts with this dataset first, then switch to the Large one)\n",
    "- Large (7850000 images, the one we used in CLEAR paper\n",
    "- Even Larger (??, I am still downloading more images, stay tuned)\n",
    "\n",
    "# I also extracted CLIP features using 3 models (ranked by model sizes, larger models may perform better):\n",
    "- ResNet50 (RN50)\n",
    "- ResNet101 (RN101)\n",
    "- ResNet50x4 (RN50x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "studied-miniature",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from prepare_dataset import get_knearest_models_func, load_bucket_dict\n",
    "import faiss_utils\n",
    "from faiss_utils import KNearestFaissFeatureChunks\n",
    "\n",
    "# Smallest size + shorter edge larger than 120px + max aspect ratio smaller than 2\n",
    "SMALLEST_DATASET = \"/scratch/zhiqiu/yfcc100m_all_new/images_minbyte_10_valid_uploaded_date_minedge_120_maxratio_2.0/\"\n",
    "# Medium size 2740000\n",
    "MEDIUM_DATASET = \"/scratch/zhiqiu/yfcc100m_all/images_minbyte_10_valid_uploaded_date_jan_31/\" \n",
    "# Large size 7850000 (the one we used in CLEAR paper)\n",
    "LARGE_DATASET = \"/scratch/zhiqiu/yfcc100m_all/images_minbyte_10_valid_uploaded_date_feb_18/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "intermediate-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a cell of customary concept group. Then save this concept group locally? (User, date, concept lists)\n",
    "# Prepare a script to collect the concept group.\n",
    "# Prepare a script to save the concept group locally.\n",
    "# Teach them about chmod for public access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-bench",
   "metadata": {},
   "source": [
    "# Modify the below cell to create your own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "published-migration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The identifier (name) of dataset is CLEAR10-zhiqiul-2021-07-28\n",
      "The dataset information will be saved at /data3/zhiqiul/clear_datasets/CLEAR10-zhiqiul-2021-07-28/concept_group_dict.pickle\n",
      "Dataset already exists\n"
     ]
    }
   ],
   "source": [
    "# This cell contains a group of visual concepts\n",
    "concept_group_dict = {\n",
    "    'USERNAME' : \"zhiqiul\", # Your username\n",
    "    'DATE' : \"2021-07-28\", # Date for reference\n",
    "    'GROUPNAME' : \"CLEAR10\", # Change to your own name\n",
    "#     'GROUPNAME' : \"CLEAR10-MEDIUM\", # Change to your own name\n",
    "    'PREFIX' : \"\", # You can add a prefix to all visual concepts, such as 'a photo of'\n",
    "    'ALLOW_OVERLAP' : False, # If False, images appear in multiple categories will be removed\n",
    "    'FOLDER_PATH' : LARGE_DATASET, # The path to the dataset created by prepare_dataset.py\n",
    "#     'FOLDER_PATH' : MEDIUM_DATASET, # The path to the dataset created by prepare_dataset.py\n",
    "    'CLIP_MODEL' : 'RN50', # The pre-trained model used for extracting CLIP features\n",
    "    'NUM_OF_BUCKETS' : 11, # The number of buckets (segments) in the dataset\n",
    "    'NUM_OF_IMAGES_PER_CLASS_PER_BUCKET' : 600, # The number of images to retrieve per class per bucket\n",
    "    'NUM_OF_IMAGES_PER_CLASS_PER_BUCKET_TO_QUERY' : 16000, # The number of images to query (this number must be larger than the above).\n",
    "    'BACKGROUND' : True, # If True, add an additional negative class\n",
    "    'NEGATIVE_RATIO' : 0.1, # The ratio of negative samples per class to keep\n",
    "    'SAVE_PATH' : \"/data3/zhiqiul/clear_datasets\", # The images will be saved at this path.\n",
    "    'GROUP' : [\n",
    "        'laptop',\n",
    "        'camera',\n",
    "        'bus',\n",
    "        'sweater',\n",
    "        'dress',\n",
    "        'racing',\n",
    "        'hockey',\n",
    "        'cosplay',\n",
    "        'baseball',\n",
    "        'soccer',\n",
    "    ]\n",
    "}\n",
    "\n",
    "from prepare_concepts import get_dataset_name, get_save_path, get_concept_group_dict_path, prepare_dataset_folder\n",
    "\n",
    "# Here I copied all the function definitions in prepare_concepts.py for reference\n",
    "\n",
    "# def get_dataset_name(concept_group_dict):\n",
    "#     return \"-\".join([concept_group_dict['GROUPNAME'], concept_group_dict[\"USERNAME\"], concept_group_dict['DATE']])\n",
    "\n",
    "# def get_save_path(concept_group_dict):\n",
    "#     dataset_name = get_dataset_name(concept_group_dict)\n",
    "#     save_path = os.path.join(concept_group_dict['SAVE_PATH'], dataset_name)\n",
    "#     return save_path\n",
    "    \n",
    "# def get_concept_group_dict_path(concept_group_dict):\n",
    "#     \"\"\"Save concept_group_dict at this path\n",
    "#     \"\"\"\n",
    "#     save_path = get_save_path(concept_group_dict)\n",
    "#     return os.path.join(save_path, \"concept_group_dict.pickle\")\n",
    "\n",
    "# def prepare_dataset_folder(concept_group_dict):\n",
    "#     save_path = get_save_path(concept_group_dict)\n",
    "#     concept_group_dict_path = get_concept_group_dict_path(concept_group_dict)\n",
    "#     if os.path.exists(save_path):\n",
    "#         if not os.path.exists(concept_group_dict_path):\n",
    "#             print(\"Missing concept group dict\")\n",
    "#             os.rmdir(save_path)\n",
    "#             return\n",
    "#         else:\n",
    "#             concept_group_dict_saved = load_pickle(concept_group_dict_path)\n",
    "#             if concept_group_dict_saved == concept_group_dict:\n",
    "#                 print('Dataset already exists')\n",
    "#             else:\n",
    "#                 print(f'Dataset already exists at {save_path} and has conflicting options. Please double check.')\n",
    "#     else:\n",
    "#         os.makedirs(save_path)\n",
    "#         save_obj_as_pickle(concept_group_dict_path, concept_group_dict)\n",
    "#         for bucket_idx in range(concept_group_dict['NUM_OF_BUCKETS']):\n",
    "#             for concept in concept_group_dict['GROUP']:\n",
    "#                 os.makedirs(os.path.join(save_path, str(bucket_idx), concept))\n",
    "#             if concept_group_dict['BACKGROUND']:\n",
    "#                 os.makedirs(os.path.join(save_path, str(bucket_idx), 'BACKGROUND'))\n",
    "#         print(f\"Save dataset folder at {save_path}\")\n",
    "            \n",
    "    \n",
    "print(f\"The identifier (name) of dataset is \" + get_dataset_name(concept_group_dict))\n",
    "print(f\"The dataset information will be saved at {get_concept_group_dict_path(concept_group_dict)}\")\n",
    "prepare_dataset_folder(concept_group_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-sweet",
   "metadata": {},
   "source": [
    "# The below cell will generate a script for you to run to collect the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "documented-diary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python prepare_concepts.py --concept_group_dict /data3/zhiqiul/clear_datasets/CLEAR10-zhiqiul-2021-07-28/concept_group_dict.pickle\n"
     ]
    }
   ],
   "source": [
    "def generate_python_script(concept_group_dict):\n",
    "    python_script = f\"python prepare_concepts.py --concept_group_dict {get_concept_group_dict_path(concept_group_dict)}\" \n",
    "    return python_script\n",
    "\n",
    "print(generate_python_script(concept_group_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-albania",
   "metadata": {},
   "source": [
    "# To download the images (after collection) to local computer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-grounds",
   "metadata": {},
   "source": [
    "# To allow others accessing your folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-daisy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
